# Directories
PAPERS_DIR=./papers
VECTORSTORE_DIR=./vectorstore
INGEST_RECORD=./vectorstore/ingested.json

# Chunking
CHUNK_SIZE=500
CHUNK_OVERLAP=50

# LLM Backend: "ollama" (default), "anthropic", "openai"
LLM_BACKEND=ollama

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
LLM_MODEL=gemma3:12b

# Cloud backends (uncomment and set keys when LLM_BACKEND != ollama)
# ANTHROPIC_API_KEY=
# ANTHROPIC_MODEL=claude-sonnet-4-20250514
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Retrieval
TOP_K_CANDIDATES=20
TOP_K=4
BM25_WEIGHT=0.3
DENSE_WEIGHT=0.7

# Reranking
# RERANK_BACKEND: "local" (default), "cohere", "jina"
RERANK_BACKEND=local
RERANK_MODEL=BAAI/bge-reranker-v2-m3

# Cohere reranker (when RERANK_BACKEND=cohere)
# COHERE_API_KEY=
# COHERE_RERANK_MODEL=rerank-v3.5

# Jina reranker (when RERANK_BACKEND=jina)
# JINA_API_KEY=
# JINA_RERANK_MODEL=jina-reranker-v2-base-multilingual

# Pipeline feature flags
INTENT_CLASSIFICATION_ENABLED=true
ARCHETYPE_DETECTION_ENABLED=true
QUERY_REFORMULATION_ENABLED=true
QUERY_RESOLUTION_ENABLED=true
METADATA_EXTRACTION_ENABLED=true

# Relevance checking
RELEVANCE_CHECK_ENABLED=true
USE_CROSS_ENCODER_RELEVANCE=true
RELEVANCE_THRESHOLD=0.6
MAX_RETRIEVAL_RETRIES=1

# Agent / SQL
ENABLE_SQL_AGENT=false
SQL_DATABASE_PATH=
AGENT_MAX_ITERATIONS=5

# Ingestion
SUPPORTED_FORMATS=pdf,docx,xlsx
ENABLE_TABLE_EXTRACTION=true
LARGE_TABLE_THRESHOLD=100

# Session management
SESSION_TTL_SECONDS=3600

# CORS (comma-separated origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Parent document retrieval (experimental)
ENABLE_PARENT_RETRIEVAL=false
CHILD_CHUNK_SIZE=400
CHILD_CHUNK_OVERLAP=50

# Optional S3 sync for ingestion
ENABLE_S3_INGEST=false
S3_BUCKET=
S3_PREFIX=
S3_REGION=
S3_LOOKBACK_HOURS=3
