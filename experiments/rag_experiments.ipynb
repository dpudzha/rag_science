{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RAG Experimentation & Evaluation Framework\n\nThis notebook systematically evaluates different RAG pipeline configurations to find optimal parameters.\nWe start with the current baseline, then iteratively change parameters and measure impact.\n\n**Papers in corpus:** ~30 scientific papers on the ATLAS ITk Pixel Detector, covering readout chips (RD53/ITkPixV2), DAQ (FELIX, YARR), optoelectronics, and module assembly."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1 \u2014 Setup & Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 golden Q&A pairs\n",
      "Sample: What CMOS technology node is the ITkPixV2 chip fabricated in?\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from eval.experiment_runner import (\n",
    "    load_golden_dataset,\n",
    "    run_experiment,\n",
    "    compare_experiments,\n",
    "    plot_comparison,\n",
    "    plot_radar,\n",
    "    ExperimentResult,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "golden = load_golden_dataset()\n",
    "print(f\"Loaded {len(golden)} golden Q&A pairs\")\n",
    "print(f\"Sample: {golden[0]['question']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading faiss.\n",
      "INFO: Successfully loaded faiss.\n",
      "INFO: BM25 index loaded from vectorstore/bm25_index.pkl\n",
      "INFO: Loading cross-encoder model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING: Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2970331b37364b568513244f12a506c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cross-encoder/ms-marco-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: [baseline] Done in 154.5s \u2014 MRR=0.860 Recall@4=0.630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Results:\n",
      "  MRR: 0.860\n",
      "  Recall@4: 0.63\n",
      "  Duration: 154.5s\n"
     ]
    }
   ],
   "source": [
    "# Run baseline with current configuration\n",
    "baseline = run_experiment(\n",
    "    name=\"baseline\",\n",
    "    config_overrides={},  # use current defaults\n",
    "    golden_dataset=golden,\n",
    "    reingest=False,\n",
    ")\n",
    "\n",
    "all_results = [baseline]\n",
    "print(f\"\\nBaseline Results:\")\n",
    "print(f\"  MRR: {baseline.metrics['mrr']:.3f}\")\n",
    "print(f\"  Recall@4: {baseline.metrics.get('recall@4', 'N/A')}\")\n",
    "print(f\"  Duration: {baseline.duration_seconds:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>mrr</th>\n",
       "      <th>recall@4</th>\n",
       "      <th>sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What CMOS technology node is the ITkPixV2 chip...</td>\n",
       "      <td>According to the paper \"The ITkPixV2 chip\" (Pa...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[Go\u0308ttingen_RD53B_Seminar_06-21.pdf, 2502.0509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the pixel size of ITkPixV2?</td>\n",
       "      <td>According to Table 1 in the paper \"ATLAS ITk P...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[2502.05097v1.pdf, 1_ATLAS ITk Pixel Detector ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many modules make up the ITk Pixel detecto...</td>\n",
       "      <td>According to the provided papers, the ITk Pixe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[6_ATLAS ITk pixel detector overview.pdf, Mo\u0308b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the trigger rate requirement for the I...</td>\n",
       "      <td>According to Section 0.4 GHz/cm2, the design r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[2502.05097v1.pdf, 2502.05097v1.pdf, 2502.0509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the specifications of the FELIX FLX-7...</td>\n",
       "      <td>According to the provided papers, the FELIX FL...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[2_FELIX_the_Detector_Interface_for_the_ATLAS_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many Optoboards are required for the ITk P...</td>\n",
       "      <td>According to the provided papers, there are a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[2_AT2_IP_MG_0010_v2.7.pdf, 1_ACES20200528_Pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What radiation tolerance is required for the i...</td>\n",
       "      <td>According to Chapter 15 of the provided paper ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[4_20230905_TIPP2023.pdf, introduction_guide.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What powering scheme do RD53 chips use and why?</td>\n",
       "      <td>The RD53 chips use a novel serial powering sch...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[introduction_guide.pdf, Loddo_PSD13.pdf, intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are the differences between the 3D and pl...</td>\n",
       "      <td>According to the provided papers, the main dif...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[6_ATLAS ITk pixel detector overview.pdf, 1_AT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What threshold and noise performance was measu...</td>\n",
       "      <td>According to the paper \"Threshold tuning\" by M...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[ITkPixV2_Mironova.pdf, Mironova_PSD13.pdf, Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the total pixel array size of the ATLA...</td>\n",
       "      <td>According to Table 1, the dimensions for the A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[rd53cATLAS1v92.pdf, rd53cATLAS1v92.pdf, rd53c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the expected peak luminosity at the HL...</td>\n",
       "      <td>According to the provided papers, the expected...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[Go\u0308ttingen_RD53B_Seminar_06-21.pdf, 1_ATLAS I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How does the FELIX software performance compar...</td>\n",
       "      <td>According to the provided papers, the FELIX so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[2_FELIX_the_Detector_Interface_for_the_ATLAS_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What power distribution system is used on the ...</td>\n",
       "      <td>According to the provided papers, the power di...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[2_AT2_IP_MG_0010_v2.7.pdf, 1_ACES20200528_Pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What were the YARR processing times when runni...</td>\n",
       "      <td>I don't have enough information in the provide...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[1_Alkakhi_2024_J._Inst._19_C11013.pdf, 1_Alka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What data encoding format is used for the read...</td>\n",
       "      <td>According to Chapter 8, \"Readout formatting an...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[introduction_guide.pdf, rd53cATLAS1v92.pdf, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What are the main differences between the ATLA...</td>\n",
       "      <td>According to the provided papers, the main dif...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[rd53cATLAS1v92.pdf, 1_RD53B_ATLAS_Main.pdf, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What monitoring capabilities does the MOPS chi...</td>\n",
       "      <td>According to the provided papers, the MOPS (Mo...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[3_Optosystem status - Bern ATLAS Team.pdf, 2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How many FELIX cards are deployed for ATLAS an...</td>\n",
       "      <td>According to the provided papers, about 100 FE...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[2_FELIX_the_Detector_Interface_for_the_ATLAS_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What module assembly precision is required for...</td>\n",
       "      <td>According to the provided papers, the module a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[5_ATL-ITK-SLIDE-2024-008.pdf, 3_-Andreazza_IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the expected rate of Single Event Upse...</td>\n",
       "      <td>According to the paper \"RD53 pixel chips for t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[Loddo_PSD13.pdf, introduction_guide.pdf, intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How many readout lanes does ITkPixV2 have and ...</td>\n",
       "      <td>According to the provided papers, ITkPixV2 has...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[2502.05097v1.pdf, 2502.05097v1.pdf, 2502.0509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the GBT protocol link speed and frame ...</td>\n",
       "      <td>According to the provided papers, the GBT prot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[2_FELIX_the_Detector_Interface_for_the_ATLAS_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How many pixel modules are planned for the out...</td>\n",
       "      <td>I don't have enough information in the provide...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[4_ATL-ITK-PROC-2022-014.pdf, 4_ATL-ITK-PROC-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What is the physical size of a pixel core in t...</td>\n",
       "      <td>According to the provided context, the physica...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[rd53cATLAS1v92.pdf, 1_RD53B_ATLAS_Main.pdf, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What CMOS technology node is the ITkPixV2 chip...   \n",
       "1                 What is the pixel size of ITkPixV2?   \n",
       "2   How many modules make up the ITk Pixel detecto...   \n",
       "3   What is the trigger rate requirement for the I...   \n",
       "4   What are the specifications of the FELIX FLX-7...   \n",
       "5   How many Optoboards are required for the ITk P...   \n",
       "6   What radiation tolerance is required for the i...   \n",
       "7     What powering scheme do RD53 chips use and why?   \n",
       "8   What are the differences between the 3D and pl...   \n",
       "9   What threshold and noise performance was measu...   \n",
       "10  What is the total pixel array size of the ATLA...   \n",
       "11  What is the expected peak luminosity at the HL...   \n",
       "12  How does the FELIX software performance compar...   \n",
       "13  What power distribution system is used on the ...   \n",
       "14  What were the YARR processing times when runni...   \n",
       "15  What data encoding format is used for the read...   \n",
       "16  What are the main differences between the ATLA...   \n",
       "17  What monitoring capabilities does the MOPS chi...   \n",
       "18  How many FELIX cards are deployed for ATLAS an...   \n",
       "19  What module assembly precision is required for...   \n",
       "20  What is the expected rate of Single Event Upse...   \n",
       "21  How many readout lanes does ITkPixV2 have and ...   \n",
       "22  What is the GBT protocol link speed and frame ...   \n",
       "23  How many pixel modules are planned for the out...   \n",
       "24  What is the physical size of a pixel core in t...   \n",
       "\n",
       "                                               answer  mrr  recall@4  \\\n",
       "0   According to the paper \"The ITkPixV2 chip\" (Pa...  0.5     0.500   \n",
       "1   According to Table 1 in the paper \"ATLAS ITk P...  1.0     0.333   \n",
       "2   According to the provided papers, the ITk Pixe...  1.0     0.333   \n",
       "3   According to Section 0.4 GHz/cm2, the design r...  1.0     0.333   \n",
       "4   According to the provided papers, the FELIX FL...  1.0     1.000   \n",
       "5   According to the provided papers, there are a ...  1.0     1.000   \n",
       "6   According to Chapter 15 of the provided paper ...  1.0     0.750   \n",
       "7   The RD53 chips use a novel serial powering sch...  1.0     0.333   \n",
       "8   According to the provided papers, the main dif...  1.0     0.667   \n",
       "9   According to the paper \"Threshold tuning\" by M...  1.0     1.000   \n",
       "10  According to Table 1, the dimensions for the A...  1.0     0.333   \n",
       "11  According to the provided papers, the expected...  0.5     0.333   \n",
       "12  According to the provided papers, the FELIX so...  1.0     1.000   \n",
       "13  According to the provided papers, the power di...  1.0     1.000   \n",
       "14  I don't have enough information in the provide...  1.0     1.000   \n",
       "15  According to Chapter 8, \"Readout formatting an...  1.0     0.500   \n",
       "16  According to the provided papers, the main dif...  1.0     0.333   \n",
       "17  According to the provided papers, the MOPS (Mo...  0.5     1.000   \n",
       "18  According to the provided papers, about 100 FE...  1.0     1.000   \n",
       "19  According to the provided papers, the module a...  0.0     0.000   \n",
       "20  According to the paper \"RD53 pixel chips for t...  1.0     1.000   \n",
       "21  According to the provided papers, ITkPixV2 has...  1.0     0.500   \n",
       "22  According to the provided papers, the GBT prot...  1.0     1.000   \n",
       "23  I don't have enough information in the provide...  0.0     0.000   \n",
       "24  According to the provided context, the physica...  1.0     0.500   \n",
       "\n",
       "                                              sources  \n",
       "0   [Go\u0308ttingen_RD53B_Seminar_06-21.pdf, 2502.0509...  \n",
       "1   [2502.05097v1.pdf, 1_ATLAS ITk Pixel Detector ...  \n",
       "2   [6_ATLAS ITk pixel detector overview.pdf, Mo\u0308b...  \n",
       "3   [2502.05097v1.pdf, 2502.05097v1.pdf, 2502.0509...  \n",
       "4   [2_FELIX_the_Detector_Interface_for_the_ATLAS_...  \n",
       "5   [2_AT2_IP_MG_0010_v2.7.pdf, 1_ACES20200528_Pos...  \n",
       "6   [4_20230905_TIPP2023.pdf, introduction_guide.p...  \n",
       "7   [introduction_guide.pdf, Loddo_PSD13.pdf, intr...  \n",
       "8   [6_ATLAS ITk pixel detector overview.pdf, 1_AT...  \n",
       "9   [ITkPixV2_Mironova.pdf, Mironova_PSD13.pdf, Go...  \n",
       "10  [rd53cATLAS1v92.pdf, rd53cATLAS1v92.pdf, rd53c...  \n",
       "11  [Go\u0308ttingen_RD53B_Seminar_06-21.pdf, 1_ATLAS I...  \n",
       "12  [2_FELIX_the_Detector_Interface_for_the_ATLAS_...  \n",
       "13  [2_AT2_IP_MG_0010_v2.7.pdf, 1_ACES20200528_Pos...  \n",
       "14  [1_Alkakhi_2024_J._Inst._19_C11013.pdf, 1_Alka...  \n",
       "15  [introduction_guide.pdf, rd53cATLAS1v92.pdf, 1...  \n",
       "16  [rd53cATLAS1v92.pdf, 1_RD53B_ATLAS_Main.pdf, M...  \n",
       "17  [3_Optosystem status - Bern ATLAS Team.pdf, 2_...  \n",
       "18  [2_FELIX_the_Detector_Interface_for_the_ATLAS_...  \n",
       "19  [5_ATL-ITK-SLIDE-2024-008.pdf, 3_-Andreazza_IT...  \n",
       "20  [Loddo_PSD13.pdf, introduction_guide.pdf, intr...  \n",
       "21  [2502.05097v1.pdf, 2502.05097v1.pdf, 2502.0509...  \n",
       "22  [2_FELIX_the_Detector_Interface_for_the_ATLAS_...  \n",
       "23  [4_ATL-ITK-PROC-2022-014.pdf, 4_ATL-ITK-PROC-2...  \n",
       "24  [rd53cATLAS1v92.pdf, 1_RD53B_ATLAS_Main.pdf, r...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View per-question baseline results\n",
    "baseline_df = pd.DataFrame(baseline.per_question)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Baseline Error Analysis\n\nInspect failures (MRR=0) and partial hits (MRR<1) to guide which experiments to prioritize.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load expected sources for comparison\nexpected_map = {item[\"question\"]: item[\"expected_sources\"] for item in golden}\n\nerror_df = baseline_df.copy()\nerror_df[\"expected\"] = error_df[\"question\"].map(expected_map)\n\n# Complete misses\nprint(\"=== COMPLETE MISSES (MRR = 0.0) ===\\n\")\nmisses = error_df[error_df[\"mrr\"] == 0.0]\nfor _, row in misses.iterrows():\n    print(f\"Q: {row['question'][:80]}...\")\n    print(f\"  Expected: {row['expected']}\")\n    print(f\"  Got:      {row['sources']}\")\n    print()\n\n# Partial hits (correct source found but not ranked first)\nprint(\"=== PARTIAL HITS (0 < MRR < 1) ===\\n\")\npartial = error_df[(error_df[\"mrr\"] > 0) & (error_df[\"mrr\"] < 1)]\nfor _, row in partial.iterrows():\n    print(f\"Q: {row['question'][:80]}...\")\n    print(f\"  MRR={row['mrr']:.2f}, Recall@4={row['recall@4']:.2f}\")\n    print(f\"  Expected: {row['expected']}\")\n    print(f\"  Got:      {row['sources']}\")\n    print()\n\n# LLM failures (retrieval ok but answer says \"I don't have enough\")\nprint(\"=== LLM FAILURES (good retrieval, bad answer) ===\\n\")\nllm_fails = error_df[\n    (error_df[\"mrr\"] >= 1.0) &\n    error_df[\"answer\"].str.contains(\"don't have enough\", case=False, na=False)\n]\nfor _, row in llm_fails.iterrows():\n    print(f\"Q: {row['question'][:80]}...\")\n    print(f\"  Recall@4={row['recall@4']:.2f}\")\n    print(f\"  Sources: {row['sources']}\")\n    print()\n\nprint(f\"Summary: {len(misses)} misses, {len(partial)} partial, {len(llm_fails)} LLM failures out of {len(error_df)} questions\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2 \u2014 Experiment: Chunk Size\n",
    "\n",
    "Test different chunk sizes to find the optimal balance between context granularity and completeness.\n",
    "Each chunk size requires re-ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = [500, 1000, 1500, 2000, 3000]\n",
    "chunk_results = []\n",
    "\n",
    "for cs in chunk_sizes:\n",
    "    overlap = cs // 7  # keep roughly similar overlap ratio\n",
    "    result = run_experiment(\n",
    "        name=f\"chunk_{cs}\",\n",
    "        config_overrides={\n",
    "            \"CHUNK_SIZE\": cs,\n",
    "            \"CHUNK_OVERLAP\": overlap,\n",
    "        },\n",
    "        golden_dataset=golden,\n",
    "        reingest=True,\n",
    "    )\n",
    "    chunk_results.append(result)\n",
    "    print(f\"  chunk_size={cs}: MRR={result.metrics['mrr']:.3f}\")\n",
    "\n",
    "all_results.extend(chunk_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = compare_experiments(chunk_results)\n",
    "display(chunk_df)\n",
    "\n",
    "fig = plot_comparison(chunk_df, title=\"Chunk Size Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3 \u2014 Experiment: Retrieval Weights\n",
    "\n",
    "Vary BM25/Dense weight ratios. No re-ingestion needed \u2014 just changes retriever scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_configs = [\n",
    "    (\"dense_only\", 0.0, 1.0),\n",
    "    (\"bm25_only\", 1.0, 0.0),\n",
    "    (\"bm25_0.1\", 0.1, 0.9),\n",
    "    (\"bm25_0.3\", 0.3, 0.7),  # current default\n",
    "    (\"bm25_0.5\", 0.5, 0.5),\n",
    "    (\"bm25_0.7\", 0.7, 0.3),\n",
    "]\n",
    "\n",
    "weight_results = []\n",
    "for name, bm25_w, dense_w in weight_configs:\n",
    "    result = run_experiment(\n",
    "        name=name,\n",
    "        config_overrides={\n",
    "            \"BM25_WEIGHT\": bm25_w,\n",
    "            \"DENSE_WEIGHT\": dense_w,\n",
    "        },\n",
    "        golden_dataset=golden,\n",
    "        reingest=False,\n",
    "    )\n",
    "    weight_results.append(result)\n",
    "    print(f\"  {name}: MRR={result.metrics['mrr']:.3f}\")\n",
    "\n",
    "all_results.extend(weight_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = compare_experiments(weight_results)\n",
    "display(weight_df)\n",
    "\n",
    "fig = plot_comparison(weight_df, title=\"Retrieval Weight Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4 \u2014 Experiment: Top-K and Reranking\n",
    "\n",
    "Vary TOP_K (final documents) and TOP_K_CANDIDATES (pre-reranking pool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_configs = [\n",
    "    (\"k2_c10\", 2, 10),\n",
    "    (\"k2_c20\", 2, 20),\n",
    "    (\"k4_c10\", 4, 10),\n",
    "    (\"k4_c20\", 4, 20),  # current default\n",
    "    (\"k4_c40\", 4, 40),\n",
    "    (\"k6_c20\", 6, 20),\n",
    "    (\"k6_c40\", 6, 40),\n",
    "    (\"k8_c20\", 8, 20),\n",
    "    (\"k8_c40\", 8, 40),\n",
    "]\n",
    "\n",
    "topk_results = []\n",
    "for name, k, candidates in topk_configs:\n",
    "    result = run_experiment(\n",
    "        name=name,\n",
    "        config_overrides={\n",
    "            \"TOP_K\": k,\n",
    "            \"TOP_K_CANDIDATES\": candidates,\n",
    "        },\n",
    "        golden_dataset=golden,\n",
    "        reingest=False,\n",
    "    )\n",
    "    topk_results.append(result)\n",
    "    recall_key = f\"recall@{k}\"\n",
    "    print(f\"  {name}: MRR={result.metrics['mrr']:.3f}, {recall_key}={result.metrics[recall_key]:.3f}\")\n",
    "\n",
    "all_results.extend(topk_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_df = compare_experiments(topk_results)\n",
    "display(topk_df)\n",
    "\n",
    "fig = plot_comparison(topk_df, metrics=[\"mrr\"], title=\"Top-K / Candidates Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Section 4b \u2014 Experiment: Candidate Pool Size (fixed TOP_K=4)\n\nIsolate the effect of widening the pre-reranking candidate pool. More candidates means\nthe cross-encoder sees more documents, increasing the chance of surfacing niche papers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "candidate_pools = [10, 20, 30, 40, 60, 80]\ncandidate_results = []\n\nfor c in candidate_pools:\n    result = run_experiment(\n        name=f\"candidates_{c}\",\n        config_overrides={\n            \"TOP_K\": 4,\n            \"TOP_K_CANDIDATES\": c,\n        },\n        golden_dataset=golden,\n        reingest=False,\n    )\n    candidate_results.append(result)\n    print(f\"  candidates={c}: MRR={result.metrics['mrr']:.3f}, Recall@4={result.metrics['recall@4']:.3f}\")\n\nall_results.extend(candidate_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cand_df = compare_experiments(candidate_results)\ndisplay(cand_df)\n\nfig = plot_comparison(cand_df, title=\"Candidate Pool Size (fixed TOP_K=4)\")\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5 \u2014 Experiment: Embedding Models\n",
    "\n",
    "Compare different Ollama embedding models. Requires re-ingestion per model.\n",
    "\n",
    "**Note:** Make sure models are pulled in Ollama before running (`ollama pull <model>`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models = [\n",
    "    \"nomic-embed-text\",      # current default\n",
    "    \"mxbai-embed-large\",\n",
    "]\n",
    "\n",
    "embedding_results = []\n",
    "for model in embedding_models:\n",
    "    result = run_experiment(\n",
    "        name=f\"embed_{model}\",\n",
    "        config_overrides={\"EMBEDDING_MODEL\": model},\n",
    "        golden_dataset=golden,\n",
    "        reingest=True,\n",
    "    )\n",
    "    embedding_results.append(result)\n",
    "    print(f\"  {model}: MRR={result.metrics['mrr']:.3f}\")\n",
    "\n",
    "all_results.extend(embedding_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = compare_experiments(embedding_results)\n",
    "display(embed_df)\n",
    "\n",
    "fig = plot_comparison(embed_df, title=\"Embedding Model Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6 \u2014 Experiment: LLM Models\n",
    "\n",
    "Compare generation quality across different LLMs. Same retrieval, different generation.\n",
    "\n",
    "**Note:** Pull models first with `ollama pull <model>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_models = [\n",
    "    \"llama3.1:8b\",   # current default\n",
    "    # Add more models as available in your Ollama instance, e.g.:\n",
    "    # \"mistral:7b\",\n",
    "    # \"gemma2:9b\",\n",
    "]\n",
    "\n",
    "llm_results = []\n",
    "for model in llm_models:\n",
    "    result = run_experiment(\n",
    "        name=f\"llm_{model}\",\n",
    "        config_overrides={\"LLM_MODEL\": model},\n",
    "        golden_dataset=golden,\n",
    "        reingest=False,\n",
    "    )\n",
    "    llm_results.append(result)\n",
    "    print(f\"  {model}: MRR={result.metrics['mrr']:.3f}\")\n",
    "\n",
    "all_results.extend(llm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_df = compare_experiments(llm_results)\n",
    "display(llm_df)\n",
    "\n",
    "fig = plot_comparison(llm_df, title=\"LLM Model Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Section 7 \u2014 Experiment: Parent-Document Retrieval\n\nUse small child chunks for retrieval precision, but expand to larger parent chunks when\npassing context to the LLM. This helps when retrieval finds the right spot but the chunk\nis too small for the LLM to synthesize a full answer (e.g. Q14 YARR processing times).\n\n**Requires re-ingestion** to create child\u2192parent mappings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "parent_configs = [\n    (\"parent_off\", False, 400, 50),         # baseline (no parent retrieval)\n    (\"parent_c300\", True, 300, 50),          # smaller child chunks\n    (\"parent_c400\", True, 400, 50),          # default child size\n    (\"parent_c200\", True, 200, 30),          # very small child chunks\n]\n\nparent_results = []\nfor name, enabled, child_size, child_overlap in parent_configs:\n    result = run_experiment(\n        name=name,\n        config_overrides={\n            \"ENABLE_PARENT_RETRIEVAL\": enabled,\n            \"CHILD_CHUNK_SIZE\": child_size,\n            \"CHILD_CHUNK_OVERLAP\": child_overlap,\n        },\n        golden_dataset=golden,\n        reingest=True,\n    )\n    parent_results.append(result)\n    print(f\"  {name}: MRR={result.metrics['mrr']:.3f}, Recall@4={result.metrics['recall@4']:.3f}\")\n\nall_results.extend(parent_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "parent_df = compare_experiments(parent_results)\ndisplay(parent_df)\n\nfig = plot_comparison(parent_df, title=\"Parent-Document Retrieval Comparison\")\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Section 8 \u2014 Combined Best Configuration\n\nTake the winning parameters from each experiment above and combine them into a single run.\nUpdate the overrides below based on your results from previous sections."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fill in the best values from your experiments above\nbest_config = {\n    # \"CHUNK_SIZE\": 1500,           # update with best from Section 2\n    # \"CHUNK_OVERLAP\": 200,         # update with best from Section 2\n    # \"BM25_WEIGHT\": 0.3,           # update with best from Section 3\n    # \"DENSE_WEIGHT\": 0.7,          # update with best from Section 3\n    # \"TOP_K\": 4,                   # update with best from Section 4\n    # \"TOP_K_CANDIDATES\": 20,       # update with best from Section 4/4b\n    # \"EMBEDDING_MODEL\": \"nomic-embed-text\",  # update with best from Section 5\n    # \"LLM_MODEL\": \"llama3.1:8b\",   # update with best from Section 6\n}\n\n# Uncomment the lines above and set values, then run:\nif best_config:\n    needs_reingest = any(k in best_config for k in [\"CHUNK_SIZE\", \"CHUNK_OVERLAP\", \"EMBEDDING_MODEL\", \"CHILD_CHUNK_SIZE\"])\n    combined = run_experiment(\n        name=\"combined_best\",\n        config_overrides=best_config,\n        golden_dataset=golden,\n        reingest=needs_reingest,\n    )\n    all_results.append(combined)\n    print(f\"\\nCombined Best Results:\")\n    print(f\"  MRR: {combined.metrics['mrr']:.3f}\")\n    print(f\"  Recall@4: {combined.metrics.get('recall@4', 'N/A')}\")\n    print(f\"  Duration: {combined.duration_seconds:.1f}s\")\n\n    # Per-question comparison vs baseline\n    combined_df = pd.DataFrame(combined.per_question)\n    comparison = baseline_df[[\"question\", \"mrr\", \"recall@4\"]].copy()\n    comparison.columns = [\"question\", \"baseline_mrr\", \"baseline_recall\"]\n    comparison[\"combined_mrr\"] = combined_df[\"mrr\"]\n    comparison[\"combined_recall\"] = combined_df[\"recall@4\"]\n    comparison[\"mrr_delta\"] = comparison[\"combined_mrr\"] - comparison[\"baseline_mrr\"]\n    display(comparison[comparison[\"mrr_delta\"] != 0].sort_values(\"mrr_delta\"))\nelse:\n    print(\"Uncomment and fill in best_config values from your experiments above.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Section 9 \u2014 Results Dashboard\n\nCombined comparison of all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined comparison table\n",
    "full_df = compare_experiments(all_results)\n",
    "display(full_df.sort_values(\"mrr\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best configuration summary\n",
    "if \"mrr\" in full_df.columns:\n",
    "    best_idx = full_df[\"mrr\"].idxmax()\n",
    "    print(f\"Best experiment by MRR: {best_idx}\")\n",
    "    print(f\"  MRR = {full_df.loc[best_idx, 'mrr']:.3f}\")\n",
    "    print(f\"\\nFull config:\")\n",
    "    display(full_df.loc[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of all retrieval metrics across experiments\n",
    "metric_cols = [c for c in full_df.columns if c in {\n",
    "    \"mrr\", \"recall@2\", \"recall@4\", \"recall@6\", \"recall@8\",\n",
    "    \"context_precision\", \"context_recall\", \"answer_relevancy\", \"faithfulness\",\n",
    "}]\n",
    "\n",
    "if metric_cols:\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, len(full_df) * 0.4)))\n",
    "    heatmap_data = full_df[metric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    im = ax.imshow(heatmap_data.values, cmap=\"YlGn\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "    ax.set_xticks(range(len(metric_cols)))\n",
    "    ax.set_xticklabels([m.replace('_', ' ').title() for m in metric_cols], rotation=45, ha=\"right\")\n",
    "    ax.set_yticks(range(len(heatmap_data)))\n",
    "    ax.set_yticklabels(heatmap_data.index)\n",
    "    # Add text annotations\n",
    "    for i in range(len(heatmap_data)):\n",
    "        for j in range(len(metric_cols)):\n",
    "            val = heatmap_data.iloc[i, j]\n",
    "            if pd.notna(val):\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "    plt.colorbar(im, ax=ax, label=\"Score\")\n",
    "    ax.set_title(\"All Experiments \u2014 Metrics Heatmap\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart for top experiments\n",
    "# Select top 5 experiments by MRR for readability\n",
    "if \"mrr\" in full_df.columns and len(full_df) > 2:\n",
    "    top5 = full_df.nlargest(5, \"mrr\")\n",
    "    fig = plot_radar(top5, title=\"Top 5 Experiments \u2014 Radar Chart\")\n",
    "    if fig:\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}