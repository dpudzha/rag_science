{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal RAG Experiments Notebook\\n",
    "\\n",
    "This notebook implements a compact end-to-end RAG workflow:\\n",
    "1. Load minimal documents (`text`, `source`).\\n",
    "2. Chunk into fixed sentence windows (default: 5 sentences).\\n",
    "3. Build a golden dataset with `question`, `answer`, `relevant_chunks`.\\n",
    "4. Generate embeddings for chunks and build a FAISS index.\\n",
    "5. Initialize a minimal RAG architecture (tokenizer + retriever + sequence model).\\n",
    "6. Run queries, retrieve chunks, generate answers, and score retrieval with Recall@k / Precision@k.\\n",
    "7. Sweep chunk sizes / retrieval settings / embedding models for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\\n",
    "import os\\n",
    "import sys\\n",
    "import pandas as pd\\n",
    "\\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\\n",
    "if str(PROJECT_ROOT) not in sys.path:\\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\\n",
    "\\n",
    "os.chdir(PROJECT_ROOT)\\n",
    "\\n",
    "from experiments.minimal_rag_pipeline import (\\n",
    "    load_json,\\n",
    "    save_json,\\n",
    "    chunk_documents,\\n",
    "    build_golden_dataset,\\n",
    "    build_chunk_index,\\n",
    "    evaluate_retrieval,\\n",
    "    FaissRetriever,\\n",
    "    MinimalRAGSequence,\\n",
    "    run_experiment_grid,\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"experiments/data\")\\n",
    "DOCS_PATH = DATA_DIR / \"minimal_documents.json\"\\n",
    "QUESTIONS_PATH = DATA_DIR / \"minimal_golden_questions.json\"\\n",
    "CHUNKED_PATH = DATA_DIR / \"minimal_documents_chunked.json\"\\n",
    "GOLDEN_PATH = DATA_DIR / \"minimal_golden_dataset.json\"\\n",
    "\\n",
    "documents = load_json(DOCS_PATH)\\n",
    "golden_questions = load_json(QUESTIONS_PATH)\\n",
    "\\n",
    "chunked_documents, chunks = chunk_documents(documents, sentences_per_chunk=5)\\n",
    "golden_dataset = build_golden_dataset(golden_questions, chunks)\\n",
    "\\n",
    "save_json(CHUNKED_PATH, chunked_documents)\\n",
    "save_json(GOLDEN_PATH, golden_dataset)\\n",
    "\\n",
    "print(f\"Documents: {len(documents)}\")\\n",
    "print(f\"Chunks: {len(chunks)}\")\\n",
    "print(f\"Golden rows: {len(golden_dataset)}\")\\n",
    "print(f\"Chunked dataset saved to: {CHUNKED_PATH}\")\\n",
    "print(f\"Golden dataset saved to: {GOLDEN_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\\n",
    "K = 3\\n",
    "\\n",
    "chunk_index = build_chunk_index(chunks, EMBED_MODEL)\\n",
    "metrics = evaluate_retrieval(golden_dataset, chunk_index, k=K)\\n",
    "\\n",
    "print(f\"Embedding model: {EMBED_MODEL}\")\\n",
    "print(f\"Mean Precision@{K}: {metrics['mean_precision']:.3f}\")\\n",
    "print(f\"Mean Recall@{K}: {metrics['mean_recall']:.3f}\")\\n",
    "pd.DataFrame(metrics['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = FaissRetriever(chunk_index, k=K)\\n",
    "rag = MinimalRAGSequence(\\n",
    "    retriever=retriever,\\n",
    "    generator_model_name=\"google/flan-t5-small\",\\n",
    "    max_new_tokens=80,\\n",
    ")\\n",
    "\\n",
    "for item in golden_dataset:\\n",
    "    result = rag.generate(item['question'], k=K)\\n",
    "    retrieved_ids = [r['chunk_id'] for r in result['retrieved']]\\n",
    "    print(f\"Q: {item['question']}\")\\n",
    "    print(f\"A: {result['answer']}\")\\n",
    "    print(f\"Retrieved: {retrieved_ids}\")\\n",
    "    print(f\"Expected relevant: {item['relevant_chunks']}\")\\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_sizes = [3, 5, 7]\\n",
    "embedding_models = [\\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\\n",
    "    \"sentence-transformers/paraphrase-MiniLM-L3-v2\",\\n",
    "]\\n",
    "\\n",
    "experiment_results = run_experiment_grid(\\n",
    "    documents=documents,\\n",
    "    golden_questions=golden_questions,\\n",
    "    chunk_sizes=chunk_sizes,\\n",
    "    embedding_models=embedding_models,\\n",
    "    k=K,\\n",
    ")\\n",
    "\\n",
    "summary = pd.DataFrame(experiment_results)[[\\n",
    "    'chunk_size_sentences',\\n",
    "    'embedding_model',\\n",
    "    f'precision@{K}',\\n",
    "    f'recall@{K}',\\n",
    "    'num_chunks',\\n",
    "]]\\n",
    "summary.sort_values(by=[f'recall@{K}', f'precision@{K}'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
